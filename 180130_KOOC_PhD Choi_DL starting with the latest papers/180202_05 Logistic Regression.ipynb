{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT TF VERSION IS [1.1.0]\n"
     ]
    }
   ],
   "source": [
    "# Cross entopy(CE) 이론에 대해 알면 좋다.\n",
    "# p와 q의 loss를 다루기 위한 것\n",
    "# 내가 풀고 싶은 문제에 맞는 Cost function 을 고르는 것이 중요하다.\n",
    "\n",
    "# 어떠한 확률분포 2개가 있을 때 이 확률 분포 사이의 거리에 의미를 둔다.\n",
    "# p : target\n",
    "# q : estimate\n",
    "\n",
    "# Softmax 알고리즘 이야기\n",
    "# NN의 아웃풋이 나오면 모두 exp를 씌워주고 \n",
    "# 확률분포가 전부 1이내가 되고\n",
    "# 합이 1이 된다.\n",
    "\n",
    "# 우리의 Target ditribution은 원핫 코딩이 되어 있다.\n",
    "\n",
    "# Squared loss 는 p와 q의 차리를 제곱하여 에러를 보정하고자 하는 컨셉이다.\n",
    "# Squared loss 는 모든 값에 맞추고자 하는 컨셉이다.\n",
    "\n",
    "# mnist 데이터셋은 불러왔으나 컴퓨터 사양 제한으로 실제 러닝은 실행하지 않았음.\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "print (\"CURRENT TF VERSION IS [%s]\" % (tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/train-images-idx3-ubyte.gz\n",
      "Extracting data/train-labels-idx1-ubyte.gz\n",
      "Extracting data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/t10k-labels-idx1-ubyte.gz\n",
      "MNIST loaded\n"
     ]
    }
   ],
   "source": [
    "mnist      = input_data.read_data_sets('data/', one_hot=True)\n",
    "trainimg   = mnist.train.images\n",
    "trainlabel = mnist.train.labels\n",
    "testimg    = mnist.test.images\n",
    "testlabel  = mnist.test.labels\n",
    "print (\"MNIST load\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## CREATE GRAPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(\"float\", [None, 784], name=\"INPUT\") \n",
    "y = tf.placeholder(\"float\", [None, 10], name=\"TARGET\")\n",
    "with tf.variable_scope(\"PARAMETERS\"):\n",
    "    W = tf.Variable(tf.zeros([784, 10]), name=\"WEIGHT\")\n",
    "    b = tf.Variable(tf.zeros([10]), name=\"BIAS\")\n",
    "# LOGISTIC REGRESSION MODEL\n",
    "with tf.variable_scope(\"MODEL\"):\n",
    "    actv = tf.nn.softmax(tf.matmul(x, W) + b) \n",
    "# COST FUNCTION\n",
    "with tf.variable_scope(\"COST\"):\n",
    "    cost = tf.reduce_mean(-tf.reduce_sum(y*tf.log(actv), reduction_indices=1)) \n",
    "# OPTIMIZER\n",
    "learning_rate = 0.01\n",
    "optm = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "# ACCURACY\n",
    "with tf.variable_scope(\"ACCURACY\"):\n",
    "    pred = tf.equal(tf.argmax(actv, 1), tf.argmax(y, 1))    \n",
    "    accr = tf.reduce_mean(tf.cast(pred, \"float\"))\n",
    "# INITIALIZER\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## TRAIN THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_epochs = 10\n",
    "batch_size      = 100\n",
    "display_step    = 2\n",
    "# SESSION\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "# MINI-BATCH LEARNING\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0.\n",
    "    num_batch = int(mnist.train.num_examples/batch_size)\n",
    "    for i in range(num_batch): \n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        sess.run(optm, feed_dict={x: batch_xs, y: batch_ys})\n",
    "        feeds = {x: batch_xs, y: batch_ys}\n",
    "        avg_cost += sess.run(cost, feed_dict=feeds)/num_batch\n",
    "    # DISPLAY\n",
    "    if epoch % display_step == 0:\n",
    "        feeds_train = {x: batch_xs, y: batch_ys}\n",
    "        feeds_test = {x: mnist.test.images, y: mnist.test.labels}\n",
    "        train_acc = sess.run(accr, feed_dict=feeds_train)\n",
    "        test_acc = sess.run(accr, feed_dict=feeds_test)\n",
    "        print (\"Epoch: %03d/%03d cost: %.9f train_acc: %.3f test_acc: %.3f\" \n",
    "               % (epoch, training_epochs, avg_cost, train_acc, test_acc))\n",
    "print (\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## TO USE TENSORBOARD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output, Image, display, HTML\n",
    "def strip_consts(graph_def, max_const_size=32):\n",
    "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
    "    strip_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = strip_def.node.add() \n",
    "        n.MergeFrom(n0)\n",
    "        if n.op == 'Const':\n",
    "            tensor = n.attr['value'].tensor\n",
    "            size = len(tensor.tensor_content)\n",
    "            if size > max_const_size:\n",
    "                tensor.tensor_content = \"<stripped %d bytes>\"%size\n",
    "    return strip_def\n",
    "def show_graph(graph_def, max_const_size=32):\n",
    "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
    "    if hasattr(graph_def, 'as_graph_def'):\n",
    "        graph_def = graph_def.as_graph_def()\n",
    "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
    "    code = \"\"\"\n",
    "        <script>\n",
    "          function load() {{\n",
    "            document.getElementById(\"{id}\").pbtxt = {data};\n",
    "          }}\n",
    "        </script>\n",
    "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
    "        <div style=\"height:600px\">\n",
    "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
    "        </div>\n",
    "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
    "\n",
    "    iframe = \"\"\"\n",
    "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
    "    \"\"\".format(code.replace('\"', '&quot;'))\n",
    "    display(HTML(iframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "show_graph(tf.get_default_graph().as_graph_def())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
